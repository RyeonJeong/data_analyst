{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58a28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c737eaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/iris3.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dafa225c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e2ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e371311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('species', axis=1)\n",
    "y = data['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "768d93cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0              1                0               0\n",
       "1              1                0               0\n",
       "2              1                0               0\n",
       "3              1                0               0\n",
       "4              1                0               0\n",
       "..           ...              ...             ...\n",
       "145            0                0               1\n",
       "146            0                0               1\n",
       "147            0                0               1\n",
       "148            0                0               1\n",
       "149            0                0               1\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0fb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78ba64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "4              1                0               0\n",
       "29             1                0               0\n",
       "27             1                0               0\n",
       "141            0                0               1\n",
       "65             0                1               0\n",
       "34             1                0               0\n",
       "23             1                0               0\n",
       "145            0                0               1\n",
       "132            0                0               1\n",
       "74             0                1               0\n",
       "56             0                1               0\n",
       "30             1                0               0\n",
       "106            0                0               1\n",
       "50             0                1               0\n",
       "119            0                0               1\n",
       "146            0                0               1\n",
       "137            0                0               1\n",
       "127            0                0               1\n",
       "70             0                1               0\n",
       "129            0                0               1\n",
       "52             0                1               0\n",
       "1              1                0               0\n",
       "67             0                1               0\n",
       "89             0                1               0\n",
       "97             0                1               0\n",
       "0              1                0               0\n",
       "120            0                0               1\n",
       "3              1                0               0\n",
       "17             1                0               0\n",
       "117            0                0               1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab5d5e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43f4b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                60        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 191\n",
      "Trainable params: 191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))  \n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f2a209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 2.4306 - accuracy: 0.3333 - val_loss: 2.0725 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.7554 - accuracy: 0.3333 - val_loss: 1.5222 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.3275 - accuracy: 0.3333 - val_loss: 1.2006 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0826 - accuracy: 0.3333 - val_loss: 1.0195 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9434 - accuracy: 0.4000 - val_loss: 0.9079 - val_accuracy: 0.6333\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.8488 - accuracy: 0.6583 - val_loss: 0.8258 - val_accuracy: 0.6333\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.7912 - accuracy: 0.7667 - val_loss: 0.7786 - val_accuracy: 0.8000\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.7561 - accuracy: 0.8250 - val_loss: 0.7493 - val_accuracy: 0.8333\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7333 - accuracy: 0.8250 - val_loss: 0.7285 - val_accuracy: 0.8667\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.8917 - val_loss: 0.7145 - val_accuracy: 0.8667\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7017 - accuracy: 0.8250 - val_loss: 0.6962 - val_accuracy: 0.9333\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.9000 - val_loss: 0.6822 - val_accuracy: 0.8667\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.8750 - val_loss: 0.6743 - val_accuracy: 0.8667\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.9000 - val_loss: 0.6602 - val_accuracy: 0.8667\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.8750 - val_loss: 0.6555 - val_accuracy: 0.8667\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.9000 - val_loss: 0.6421 - val_accuracy: 0.8667\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.9000 - val_loss: 0.6327 - val_accuracy: 0.8667\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.8917 - val_loss: 0.6305 - val_accuracy: 0.8667\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.9250 - val_loss: 0.6126 - val_accuracy: 0.9000\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.9000 - val_loss: 0.6084 - val_accuracy: 0.8667\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.9083 - val_loss: 0.5966 - val_accuracy: 0.9000\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.9083 - val_loss: 0.5920 - val_accuracy: 0.8667\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.9167 - val_loss: 0.5801 - val_accuracy: 0.9000\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.9333 - val_loss: 0.5735 - val_accuracy: 0.8667\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.9000 - val_loss: 0.5620 - val_accuracy: 0.9000\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.9250 - val_loss: 0.5528 - val_accuracy: 0.9000\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.9250 - val_loss: 0.5419 - val_accuracy: 0.9000\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.9333 - val_loss: 0.5375 - val_accuracy: 0.9000\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.9333 - val_loss: 0.5250 - val_accuracy: 0.9000\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.9500 - val_loss: 0.5175 - val_accuracy: 0.9000\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.9250 - val_loss: 0.5057 - val_accuracy: 0.9000\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.9583 - val_loss: 0.5003 - val_accuracy: 0.9000\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.9333 - val_loss: 0.5002 - val_accuracy: 0.9000\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.9417 - val_loss: 0.4809 - val_accuracy: 0.9000\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.9417 - val_loss: 0.4742 - val_accuracy: 0.9000\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.9500 - val_loss: 0.4599 - val_accuracy: 0.9000\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.9750 - val_loss: 0.4624 - val_accuracy: 0.9000\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.9417 - val_loss: 0.4574 - val_accuracy: 0.9000\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.9500 - val_loss: 0.4378 - val_accuracy: 0.9000\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.9500 - val_loss: 0.4336 - val_accuracy: 0.9000\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.9500 - val_loss: 0.4176 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.9500 - val_loss: 0.4155 - val_accuracy: 0.9000\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.9417 - val_loss: 0.4117 - val_accuracy: 0.9000\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.9583 - val_loss: 0.4002 - val_accuracy: 0.9333\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.9667 - val_loss: 0.4050 - val_accuracy: 0.9000\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.9500 - val_loss: 0.3802 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.9583 - val_loss: 0.3839 - val_accuracy: 0.9000\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.9500 - val_loss: 0.3745 - val_accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.9500 - val_loss: 0.3605 - val_accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.9500 - val_loss: 0.3549 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=5, validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7085a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c9b6c",
   "metadata": {},
   "source": [
    "# ì´ˆìŒíŒŒ ê´‘ë¬¼ ë°ì´í„°ì…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2390193a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   0  \n",
       "1    0.0052  0.0044   0  \n",
       "2    0.0095  0.0078   0  \n",
       "3    0.0040  0.0117   0  \n",
       "4    0.0107  0.0094   0  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   1  \n",
       "204  0.0062  0.0067   1  \n",
       "205  0.0077  0.0031   1  \n",
       "206  0.0036  0.0048   1  \n",
       "207  0.0061  0.0115   1  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/sonar3.csv\", header=None)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11bc1194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    int64  \n",
      "dtypes: float64(60), int64(1)\n",
      "memory usage: 99.2 KB\n"
     ]
    }
   ],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0adc088d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    111\n",
       "0     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe74e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = data2.drop(60, axis=1)\n",
    "y2 = data2[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dc60d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "203    1\n",
       "204    1\n",
       "205    1\n",
       "206    1\n",
       "207    1\n",
       "Name: 60, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ede3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d656ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 60)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9a0ecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 24)                1464      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                250       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,725\n",
      "Trainable params: 1,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ë”¥ëŸ¬ë‹ ë„¤íŠ¸ì›Œí¬ ìƒì„±\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(24, input_dim=X_train2.shape[1],activation='relu'))\n",
    "model2.add(Dense(10, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83f5c570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5482\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6747\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.7289\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.7229\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.7530\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.7590\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7952\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.7771\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7831\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.7771\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.8253\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8012\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.8193\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8133\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.8253\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.8253\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.8373\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.8253\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.8253\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.8072\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8434\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8434\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8313\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4085 - accuracy: 0.8434\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8554\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8434\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8494\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8313\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8614\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.8614\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8554\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8675\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8554\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8614\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8554\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8675\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8795\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8494\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8855\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.9036\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8976\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8916\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8855\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8916\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8855\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.9036\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8976\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.9036\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8976\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.9036\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8916\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2688 - accuracy: 0.9096\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.9157\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.9036\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2578 - accuracy: 0.9157\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.9217\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2660 - accuracy: 0.8976\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.9217\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.9217\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9337\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9277\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9398\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9096\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9337\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9157\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9337\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9277\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.9518\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.9277\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.9458\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9458\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9518\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.9398\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9518\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.9458\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9398\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9518\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9458\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9518\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.9458\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.9398\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9458\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9398\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9578\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9578\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9578\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9578\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9639\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9578\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9578\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9578\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9639\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9578\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 939us/step - loss: 0.1512 - accuracy: 0.9639\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9458\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9699\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9518\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9398\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9458\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9578\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9157\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9699\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9639\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9699\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9639\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9759\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9699\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9639\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9759\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9759\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9639\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9759\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9699\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9699\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9759\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9699\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9639\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9759\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9699\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9759\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9759\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9819\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9819\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9759\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9759\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9819\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9819\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9940\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9819\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9819\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9880\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9880\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9880\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9940\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9819\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9880\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9880\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9880\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9880\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9940\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 0.9880\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9880\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9940\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9940\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9940\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9880\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9940\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9940\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9940\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9940\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9940\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9940\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9940\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9940\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9940\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9940\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9940\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9940\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9940\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì»´íŒŒì¼ ë° í›ˆë ¨\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model2.fit(X_train2, y_train2, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d3f908e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 306 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FD35AE5820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.8101 - accuracy: 0.8095\n",
      "loss:  0.810095489025116\n",
      "Accuracy:  0.8095238208770752\n"
     ]
    }
   ],
   "source": [
    "# ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ ê²€ì¦ model.evaluate(X_test, y_test)\n",
    "score = model2.evaluate(X_test2, y_test2)\n",
    "print('loss: ', score[0])\n",
    "print('Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43e1f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì €ìž¥í•˜ê¸° model.save('ì €ìž¥ê²½ë¡œ ë° íŒŒì¼ ì´ë¦„.hdf5')\n",
    "model.save('./model/stone_model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b4289bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1248fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = load_model('./model/stone_model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "271c989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 308 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FD3491F1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6860 - accuracy: 1.0000\n",
      "loss:  0.810095489025116\n",
      "Accuracy:  0.8095238208770752\n"
     ]
    }
   ],
   "source": [
    "score3 = model3.evaluate(X_test, y_test)\n",
    "print('loss: ', score[0])\n",
    "print('Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384b99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a0664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9e6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba2da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75d405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aadb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648908cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
